# Research-Project-Part-B

# Using NLP to travel the world

This repository has the code for analysis of Jules Verne novel "Around the World in Eighty Days".

Files in the repository:

There are two R files for this project:

1. The clean_book_1.R file downloads the novel 'Around the World in 80 Days' from Project Gutenberg, does basic cleaning of the book, and saves the data in a csv file named around_world_80_days.csv. 

2. The new.R file identifies the most common words in the book “Around the 
World in 80 Days” using text mining techniques to find the main context of the book.The analysis performed are the following:
⦁	Zipf's Law Analysis
⦁	Term Frequency and N-Gram Analysis
⦁	Term Frequency–Inverse Document Frequency (TF-IDF)
⦁	Term Frequency–Inverse Document Frequency (TF-IDF) after applying lemmatization.
⦁	Synonyms Based Term Weighting (TF-IDF extension)
⦁	Topic Modelling Using Latent Dirichlet Allocation (LDA) including the top 15 most important words and the topic distribution in chapters.
In order to use wordnet, the wordnet database was downloaded  from https://wordnet.princeton.edu/download/current-version and put in a folder called "dict".


Packages required for clean_book_1.R:
⦁	tidyverse
⦁	tidytext
⦁	gutenbergr

Packages required for new.R:
⦁	tidyverse
⦁	tidytext
⦁	ggwordcloud
⦁	topicmodels
⦁	reshape2 
⦁	zoo
⦁	textclean
⦁	wordnet
⦁	textstem

How to run the project
Take the R files and dict folder to RStudio. First run the clean_book_1.R file to get the cleaned dataset in the csv file named  "around_world_80_days.csv". This is the data we use for the new.R file.  Then run the new.R file to conduct the analysis. 

Note:
clean_book_1.R must be run first because new.R depends on file generated by running clean_book_1.R
